\RequirePackage{docswitch}
% \flag is set by the user, through the makefile:
%    make note
%    make apj
% etc.
\setjournal{\flag}

\documentclass[\docopts]{\docclass}

% You could also define the document class directly
%\documentclass[]{emulateapj}

% Custom commands from LSST DESC, see texmf/styles/lsstdesc_macros.sty
\usepackage{lsstdesc_macros}

\usepackage{graphicx}
\graphicspath{{./}{./figures/}}
\bibliographystyle{apj}

% Add your own macros here:
\input{plasticc_macros}
%\newcommand{\plasticc}{PLAsTICC}

\author{Rick Kessler,  Rahul Biswas, Alex Boucard, Mi Dai, Renee Hlozek,
Saurabh W.~Jha, Lluis Galbany, Emille Ishida, Ashish Mahabal, Kaisey Mandel, Rafael Martinez-Galarza, Daniel Mutukrishna, Tina Peters, Kara Ponder}

% ======================================================================

\begin{document}

\title{The Photometric LSST Astronomical Time-series Classification Challenge (PLAsTiCC): Data set}

%\maketitlepre

\begin{abstract}
The Photometric LSST Astronomical Time Series Classification Challenge (PLAsTiCC) is an open data challenge to classify simulated astronomical time series data in preparation for the data from the Large Synoptic Survey Telescope (LSST), that will achieve first light in 2022. We briefly describe the PLAsTiCC data set that will be tested by the Kaggle team. This note will be updated for the full release of the data to the community.

\end{abstract}

% Keywords are ignored in the LSST DESC Note style:
\dockeys{}

\maketitlepost

% ----------------------------------------------------------------------
% {% raw %}
\input{introstuff}
\section{The data}
\label{sec:thedata}

The photometric lightcurve data consist of non-homogeneously sampled, non-periodic time series with correlated errors obtained in several wavelength filters.
A hdf file over all objects will be provided. The following data are provided:

The {\plasticc} data is provided in the form of a HDF5 file, which has two kinds of information. The first
is a table listing each astronomical source in the data indexed by a unique identifier 'objid' which is a string. Each row of the table lists properties of the source. These are: 
\begin{itemize}
\item {\tt objid}: the Object ID, unique identifier, string
\item {\tt ra}: right ascension, sky coordinate: co-longitude
\item {\tt decl}: declination, sky coordinate: co-latitude,  
\item {\tt mwebv}: the value of the galactic extinction at that position on the sky, and its associated error
\item {\tt gal_specz}: the spectroscopic redshift (these values are null in the test data)
\item {\tt gal_photoz, photozerr}: the photometric redshift and its respective redshift error 
\end{itemize}

It will also contain a table of photometry with the following information:
\begin{itemize}
\item {\tt mjd}: the Modified Julian Date (MJD) of the observations
\item {\tt flux}: the measured flux in each of the specified $ugrizY$ LSST bands
\item {\tt fluxerr}: the uncertainty on the measured flux in each of the LSST bands
\item {\tt photflag}: the photometry flag is a bit mask, describing the photometry at each epoch. {\tt photflag}= 4096 indicates that there is a detection for the current epoch. {\tt photflag} = 6144 (= 4096 + 2048) means that there is a detection for the current epoch and that the 2-detection trigger was satisfied at the current epoch as well.

\clearpage
As part of the challenge, we provide a Jupyter notebook to read in the data, and a notebook to compute the metrics for the challenge.
\end{itemize}

The training set will also contain the name of the model used to simulate the transient, while the test data will not: it is the task of those participating to determine the correct model name of the test data set.


\subsection{Training data}
The training data will be a subset of $\sim 5000$ objects taken from the larger test data set. The relative rates of the data will be adjusted slightly in the training sample. This is important as it introduces a specific bias between the test and the training data. The training data will necessarily be fainter objects (as they mimic the `spectroscopic data' described above). The test data will be the full photometric survey, and so will contain objects that are fainter and in different relative proportions of the full data set. In addition, the test data will contain objects that are at greater distances away from us.

Beware that the training set is based on spectroscopic observations that classify only the brightest objects compared with LSST sensitivity. Therefore the test set will include many more distant objects with no counterpart in the training set.



% ----------------------------------------------------------------------

\section{Challenge participation}
\label{sec:conclusion}
PLAsTiCC participants must return an $M\times X$ table of classification probabilities, where $M$ is the number of objects in the test dataset, and $X$ is the number of classes, including the `other' class. The row entries sum to unity, to ensure normalised probabilities. The winner of the challenge will be the person who minimises the PLAsTiCC metric score (which is described in a separate note included in this challenge). 
For example, if the challenge was to classify a set of 3 observations into two classes of `star' or `galaxy' classes (and an `other' class), the returned classification table would be $3x3$ matrix:

\begin{table}[htbp!]
\begin{center}
\begin{tabular}{|c|c|c|c|}
Object ID & $P(star)$ & $P(galaxy)$ & $P(other)$ \\
\hline
1 & 0.6 & 0.3 & 0.1\\
2 & 0.3 & 0.3 & 0.4\\
3 & 0.55 & 0.4 & 0.05\\
\end{tabular}
\caption{An example classification table for a challenge to classify 3 objects into 3 classes}
\end{center}
\end{table}

While some members have been shielded from information about model specifics, the PLAsTiCC team involved in validating the data will not be able to participate in the challenge directly, and will only publish classifications on the data once the challenge has completed.

% ----------------------------------------------------------------------

\subsection{Acknowledgments}
The PLAsTiCC data relies numerous members of the astronomical community to provide models of astronomical transients and variables. These will be outlined in a paper to be published once the challenge is complete. While we cannot thank them by name at this stage (as this would no doubt identify the models included in the challenge), we acknowledge their contributions anonymously at this stage. This work was supported by an LSST Corporation Enabling Science grant, and a Dark Energy Science Collaboration Workshop support grant.

%%% Here is where you should add your specific acknowledgments, remembering that some standard thanks will be added via the \code{desc-tex/ack/*.tex} and \code{contributions.tex} files.

%This paper has undergone internal review in the LSST Dark Energy Science Collaboration. % REQUIRED if true

%\input{contributions} % Standard papers only: author contribution statements. For examples, see http://blogs.nature.com/nautilus/2007/11/post_12.html

% This work used TBD kindly provided by Not-A-DESC Member and benefitted from comments by Another Non-DESC person.

% Standard papers only: A.B.C. acknowledges support from grant 1234 from ...

\input{desc-tex/ack/standard} % also available: key standard_short

% This work used some telescope which is operated/funded by some agency or consortium or foundation ...

% We acknowledge the use of An-External-Tool-like-NED-or-ADS.

%{\it Facilities:} \facility{LSST}

% Include both collaboration papers and external citations:
%\bibliography{main,lsstdesc}

\end{document}

% ======================================================================
